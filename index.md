---
layout: home
title: About
---

<div style="position: relative;">
  <img src="assets/signature.png" alt="Signature" style="position: fixed; bottom: 20px; right: 20px; width: 150px; opacity: 0.6; z-index: 1000;" onerror="this.style.display='none'">
</div>

<div style="display: flex; align-items: flex-start; gap: 30px; margin-bottom: 40px;">
  <img src="assets/amirhossein.png" alt="Amirhossein Afsharrad" style="width: 200px; height: 200px; object-fit: cover;">
  <div>
    <h1 style="margin-top: 0;">Amirhossein Afsharrad</h1>
    <p style="margin: 5px 0;"><strong>PhD Candidate, Electrical Engineering</strong><br>
    Stanford University</p>
    <p style="margin: 10px 0 0 0; line-height: 1.8;">
      <strong>Email:</strong> afsharrad@stanford.edu<br>
      ðŸŽ“ <a href="https://scholar.google.com/citations?user=yuvhn2oAAAAJ" target="_blank">Google Scholar</a><br>
      ðŸ’¼ <a href="https://www.linkedin.com/in/afsharrad/" target="_blank">LinkedIn</a><br>
      ðŸ’» <a href="https://github.com/amirafsharrad" target="_blank">GitHub</a>
    </p>
  </div>
</div>

## About

I am a PhD candidate in [Electrical Engineering](https://ee.stanford.edu/) at [Stanford University](https://www.stanford.edu/), advised by [Professor Sanjay Lall](https://lall.stanford.edu/).

My current research primarily focuses on **post-training of large language models**, **LLM alignment with human preferences**, and **evaluation and reward modeling of LLMs**.

I am also interested in more theoretical problems in **optimization and reinforcement learning**, including bandit problems with safety constraints and multi-agent settings, as well as problems at the intersection of **optimization and control** such as applications of transformer models in control theory and autonomous systems. These areas were a primary focus earlier in my PhD, and I continue to work on projects in these directions.

Prior to Stanford, I received my B.Sc. in Electrical Engineering and Computer Science from [Sharif University of Technology](http://www.sharif.ir/home), where I was advised by [Prof. Mohammadali Maddah-Ali](https://maddah.umn.edu/).

## News

- **January 2026**: Our paper "Beyond Binary Preferences: A Principled Framework for Reward Modeling with Ordinal Feedback" was accepted to ICLR 2026 [[paper](https://openreview.net/forum?id=mteZOi0xyu)]
- **December 2024**: Presented "LORE: Lagrangian-Optimized Robust Embeddings for Visual Encoders" at NeurIPS 2024 in San Diego
